#RabbitMQ 七战Kafka

##异步消息模式
异步消息 可以解耦消息的 生产和处理。通常消息队列两种主要的消息模式：消息队列 和 发布/订阅模式。

###消息队列
它可以解耦 生产者 和 消费者。当消息被处理时，这个消息在队列上会被锁住或被移除，也就是 一个具体的消息只能由一个消费者消费。
如果消息处理失败，消息系统一般会把这个消息放回队列。
![消息队列]()

###发布/订阅模式
此模式(pub/sub)中，单个消息可以被多个订阅者并发地获取和处理。在许多队列系统中常用 Topic指代这种模式。
一般，订阅有两种类型：
1. 临时订阅(ephemeral):
	这种订阅只有在消费者运行时才会存在，消费者退出，相应的订阅以及尚未处理的消息就会消失；
2. 持久订阅(durable)：
	这种订阅会一直存在，直到主动删除；
![发布订阅]()
	
##RabbitMQ
常被当作一种 服务总线来使用，原生支持上述两种消息模式。
###消息队列
开箱即用的消息队列，可以直接定义一个命名队列；
###消息交换器
RabbitMQ使用消息交换器来实现发布/订阅模式。发布者可以将消息发布到消息交换器上而不用知道有哪些订阅者。
每一个订阅了 交换器的消费者 都会创建一个队列，消息交换器 也可以基于 各种路有规则 为一些订阅者过滤消息。
RabbitMQ 支持临时和持久两种订阅类型，消费者可以调用RabbitMQ的API来选择订阅类型。
根据RabbitMQ的架构设计，也可以创建一种混合方法：订阅者以组队的方式然后在组内以竞争关系去处理某个队列上的消息，这种组成为称为消费者组。
按照这种方式实现了 发布/订阅模式，同时也能很好地扩大订阅者规模(scale_up)。
![发布订阅与队列联合]()

##Kafka
Apache Kafka不是 消息中间件 的一种实现，他只是一种分布式流式系统。
- 不同于 基于队列和交换器的 RabbitMQ，Kafka的存储层是使用 分区事务日志 来实现的;
- Kafka提供流式API用于实时的流处理，也提供连接器API 用来和各种数据源集成;

### Topic
- Kafka没有实现队列，相应的它使用Topic来存储记录集；
- Kafka为每个Topic维护一个 消息分区日志，每个分区都是由 有序的不可变的记录序列组成；
- 当消息到达时，会追加到各个分区的尾部，默认情况下，Kafka使用 轮询分区器(Partitioner)把消息一致地分配到多个分区上。
- Kafka可以改变 创建消息逻辑流 的行为。
	例如，在多租户的应用中，可以根据 消息中的租户ID 创建消息流。IoT的场景中，就可以在常数级别下根据生产者的身份信息(Identity)将其映射到具体的分区上。
	确保来自相同逻辑流上的消息能够映射到相同分区，这就保证了消息能够按照顺序提供给消费者。

![Kafka生产者]()

- 消费者通过维护分区的offset来消费数据；单个消费者可以消费多个Topic；
- 消费者的数量可以伸缩到 可获取的最大分区数量，所以在创建Topic时，要考虑预期的消息吞吐量；
- 同一个Topic的消费者构成 消费者组，通过Kafka提供的API可以处理同组中不同消费者之间的分区平衡 以及 消费者当前分区偏移量的存储。

![Kafka消费者]()

###Kafka实现的消费模式
Kafka的实现很好的契合 发布/订阅模式；
- 每一个消费者组 可以独立地伸缩处理消费负载；由于消费者可以自己维护 分区偏移，所以消费者可以选择持久订阅或临时订阅，持久订阅在重启之后不会丢失偏移量，临时订阅会丢失偏移量并且每次重启之后都会从分区中最新的记录开始消费；
- Kafka的消费模式不能完全等价 消费队列模式。当然也可以创建一个Topic，以及一个拥有一个消费者的消费组，这样就可以模拟出 消息队列，不过也有缺点；
- Kafka是按照预先配置好的时间保留分区中的消息，而不管 消费者是否消费了这些数据；这种机制可以让消费者自由地重读之前的消息。另外，开发者也可以利用Kafka的存储层来实现注入事件溯源和日志审计的功能。
----
> 尽管有时候 RabbitMQ 和 Kafka可以等价来看，但是他们的实现是非常不同的，一个是 消息中间件，一个是 分布式流式系统；
----

## RabbitMQ和Kafka的显著差异
RabbitMQ 是一个消息代理，Kafka是一个分布式流式系统；
Kafka最适用于数据的流式处理，但是RabbitMQ 很难保持流式数据的顺序；
RabbitMQ 内置 重试逻辑和死信(dead-letter)交换器，但是Kafka 把这些实现逻辑交给用户来处理；
###消息顺序
####RabbitMQ
-------
RabbitMQ 文档中关于 消息顺序保证的说明：
> 发布到一个通道(channel)上的消息，用一个交换器和一个队列以及一个出口通道来传递，那么最终按照他们发送的顺序加收到 --RabbitMQ代理语义
------
换句话说，只要是单个消费者，就能保证消息的顺序；然而，一旦有多个消费者从同一个队列消费数据，那么消息的处理顺序就无法保证了；
原因就是：由于消费者消费数据之后可能会把消息再次放回(或者重传)到队列中（例如，处理失败的情况），这样就会导致消息的顺序无法保证。
我们可以限制 单个消费者的线程数为1，来保证RabbitMQ中的消息有序性；但是随着系统规模增长，单线程消费模式会严重影响消息的处理能力，所以不要轻易选择这个方案。

####Kafka
- 对于Kafka来说，他在消息处理方面提供了可靠的顺序保证，它能够保证发送到 同一Topic分区的所有消息能够按照顺序处理；
- 前面提到，Kafka默认情况下会使用 循环分区器(round-robin partitioner) 把消息放到相应的分区，不过，生产者 可以给每条消息设置 分区键(Key) 来创建数据逻辑流（比如把来自同一个设备的消息，或者属于同一租户的消息），这样来自相同流的消息就会存放到同一分区，消费者组就可以按照顺序处理。
- 但是，同一消费组中，每个分区都是由一个消费者的一个线程来处理。结果就是没办法伸缩(scale)单个分区的处理能力；
- Kafka中，可以伸缩一个Topic的分区个数，每个分区分担更少的消息，然后消费组就可以增加消费者来处理额外分区；

-----
####对比结果
Kafka获胜，因为它可以保证按顺序处理消息。
-----

###消息路由
####RabbitMQ
- RabbitMQ 可以基于定义的 订阅者路由规则 路由消息给一个消息交换器上的订阅者；
	>> 一个 主题交换器 可以通过一个叫做 routing_key的特定头 来路由消息；
  >> 一个 头部交换器 可以基于任意的消息头来路由消息。
	这两种 交换器 都能够有效地让 消费者设置他们感兴趣的消息类型。
####Kafka
- Kafka在处理消息之前是不允许消费者过滤一个Topic中的消息，一个订阅的消费者在没有异常 的情况下会接受一个分区的所有消息；
- 作为开发者，可以使用Kafka流式作业从Topic中读取消息，然后过滤，最后再把过滤的消息推送到另一个消费者订阅的Topic; 但是会需要更多的工作量，并且涉及更多的移动操作。
------
####对比结果
在消息路由和过滤方面，RabbitMQ提供了更好的支持。
------

###消息时序(timing)
####RabbitMQ 
在测定消息时间方面，RabbitMQ提供了多种能力：
1. 消息存活时间(TTL)
- 每条消息都会关联一个TTL属性，发布者可以直接设置TTL或者根据队列的策略来设置；
- 系统可以根据TTL来限制消息的有效期，如果消费者在预期时间内没有处理该消息，那么该条消息会自动从队列上被移除(并且会被移到 死信交换器上，同时在这之后的消息都会这样处理)；
- TTL对于那些有时效性的命令特别有用；

2. 延迟/预定的消息
- RabbitMQ可以通过插件的方式来支持 延迟或者预定的消息，当插件在消息交换器上启用时，生产者可以 延迟路由 消息到消费者队列的时间；
- 开发者可以调度 future命令，来设置延迟处理。

####Kafka
- Kafka在消息到达时就把它写入分区中，消费者就可以立即获取到消息；不过可以在应用层实现时序控制；
- 但是，要记住一点就是Kafka分区是追加模式的事务日志，所以不能处理消息时间（或者在分区中的位置）。
------
####对比结果
RabbitMQ获胜
------

###消息留存(retention)
####RabbitMQ 
- 消费者消费之后，消息会删除；这是无法修改的，几乎是所有消息代理设计的必备部分；
####Kafka
- Kafka会给每个Topic配置 超时时间，超时时间内消息会保留；Kafka仅仅会把它当作消息日志来看待，并不关心消费者的消费状态；
- 消费者可以不限次数地按照offset来消费消息，Kafka会周期性地检查分区中消息的留存时间，一旦超时就被删除；
- Kafka的性能不依赖于存储的大小，所以，理论上只要节点有足够的空间就不会影响其性能；
----
####对比结果
Kafka在设计之初就是保存消息的，但是RabbitMQ并不是；所以这块没有可比性，Kafka胜出；
----

###容错处理
消息处理存在两种可能的故障：
1. 瞬时故障：故障产生是由于临时问题导致的，比如网络连接、cpu负载 或者 服务崩溃。可以通过一遍遍的尝试来减轻这种故障；
2. 持久故障：故障产生是由于永久问题导致的，并且这种问题不能通过额外的重试来解决。比如软件的bug、无效的消息格式等。

作为开发者，应该问自己：“对于消息处理故障，我们应该重试多少次？每次重试间隔是多少？怎样区分瞬时或者持久故障？”
当然，不同业务领域有不同的回答，消息系统一般会给我们提供工具让我们实现解决方案。
####RabbitMQ
- RabbitMQ会提供 交付重试 和 死信交换器(DLX) 来处理消息处理故障。
- DXL的主要思路是根据配置信息自动地把路由失败的消息发送到DLX，并且在交换机上根据规则做进一步处理，比如异常重试、重试计数以及发送到“人为干预”的队列；
  (查看下面篇文章，它在RabbitMQ处理重试上提供了额外的可能模式视角。链接：https://engineering.nanit.com/rabbitmq-retries-the-full-story-ca4cc6c5b493)
- 当一个消费者正在处理或者重试某个消息时(即使是在把它返回队列之前)，其他消费者都可以并发的处理这个消息之后的其他消息；
- 当某个消费者在重试处理某条消息时，作为一个整体的消息处理逻辑不会被阻塞；所以，一个消费者可以同步地去重试处理一条消息，不管花费多长时间都不会影响整个系统的运行。

####Kafka
- Kafka没有提供RabbitMQ那种开箱即用的机制，我们需要自己在应用层提供和实现消息重试机制；
- 当一个消费者在同步处理一个特定消息时，那么同一个分区上的消息是没法被处理的；
- 消费者不能改变消息的顺序，所以我们不能够拒绝和重试一个特定消息，以及提交一个在这个消息之后的消息；Kafka的分区仅仅是一个追加模式的日志；
- 一个应用层的解决方案：把处理失败的消息 发送到一个 重试的Topic，但是这样的话我们会丢失消息顺序；
------
####对比结果
RabbitMQ是获胜的，因为它提供了一个解决这个问题的开箱即用的机制。
-----

###可扩展性
####RabbitMQ
典型的RabbitMQ部署包含3到7个节点的集群，并且这些集群也不需要把负载分散到不同的队列上，通常可以预期每秒处理几万条消息。
####Kafka
- Kafka使用顺序磁盘I/O来提高性能；
- 从Kafka使用分区的架构上来看，他在横向扩展上会优于RabbitMQ，当然RabbitMQ在纵向扩展上会有更多优势；
- Kafka大规模部署通常每秒可以处理数十万条消息，甚至每秒百万级的消息；
-----
####对比结果
尽管两个消息平台都可以处理大规模负载，但是Kafka在可扩展性方面更优于RabbitMQ，并且能够获得比RabbitMQ更高的吞吐量。
但是，大部分系统都还没达到这些极限，所以，除非在构建一个非常受欢迎的百万级用户软件，否则不需要泰关系可扩展性问题，毕竟这两个平台都可以工作的很好。
----

###消费者复杂度
####RabbitMQ
- RabbitMQ使用的是 智能代理 和 傻瓜式的消费者模式；
- 消费者注册到消费者队列，然后RabbitMQ把传进来的消息推送给消费者，也有拉取(pull)API，一般很少用；
- 根据RabbitMQ的结构设计，当负载增加的时候，消费者组可以有效地扩展消费者数量，而不需要对系统做任何改变；

####Kafka
- Kafka是 傻瓜式代理 和 智能消费者模式；
- 消费者组中的消费者需要协调他们之间的Topic分区租约，以便一个分区只由一个消费者监听；
- 消费者需要去管理和存储 分区消费偏移量，幸运的是Kafka SDK已经为我们封装了，所以不需要自己管理；
- 当负载增加时，我们只需要增加组内消费者数量，使其等于Topic分区数量；但是当负载降低时，我们不能移除之前增加的分区，这就给消费者增加了更多的工作量，当然Kafka SDK已经为我们做了这个额外的工作。

![Kafka可扩展性]()
-----
####对比结果
RabbitMQ是为了傻瓜式消费者设计的，所以胜出。
-----

##如何选择
###优先选择RabbitMQ的条件：
- 高级灵活的路由规则；
- 消息时序控制(控制 消息有效期、消息时间延迟)；
- 高级的容错处理能力(在消费者更有可能处理消息不成功的情境中的瞬时故障或持久故障)；
- 傻瓜式的消费者管理方式。

###优先选择Kafka的条件：
- 严格的消息顺序；
- 可设置消息留存时间；
- 传统解决方案无法满足的高伸缩能力。

###其他
在考虑功能性差异基础上，也要考虑非功能性差异：
- 开发者对这两个消息平台的了解程度；
- 托管云解决方案的可用性；
- 运营成本；
- 适用于我们目标栈的SDK的可用性。
-------
经验来看，通常同时使用这两个消息平台能够带来更多的好处：
- 例如，在一个事件驱动的架构系统中，我们可以使用RabbitMQ在服务之间发送命令，使用Kafka实现业务事件通知；
- 原因是：事件通知常常用于事件溯源，批量操作(ETL风格)，或者审计目的，因此Kafka的 消息留存能力 就能显得更有价值；
- 相反，命令一般需要在消费者端之间做额外的处理，并且处理可能会失败，所以需要高级的容错处理能力；


